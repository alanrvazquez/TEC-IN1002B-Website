{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Multiple Linear Regression\"\n",
        "subtitle: \"IN1002B: Introduction to Data Science Projects\"\n",
        "author: \n",
        "  - name: Alan R. Vazquez\n",
        "    affiliations:\n",
        "      - name: Department of Industrial Engineering\n",
        "format: \n",
        "  revealjs:\n",
        "    chalkboard: false\n",
        "    multiplex: true\n",
        "    footer: \"Tecnologico de Monterrey\"\n",
        "    logo: IN1002b_logo.png\n",
        "    css: style.css\n",
        "    slide-number: True\n",
        "    html-math-method: mathjax\n",
        "editor: visual\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "\n",
        "## Agenda\n",
        "\n",
        "</br>\n",
        "\n",
        "1.  Introduction\n",
        "2.  Multiple linear regression model\n",
        "3.  Parameter estimation\n",
        "\n",
        "## statsmodels library\n",
        "\n",
        "-   **statsmodels** is a powerful Python library for statistical modeling, data analysis, and hypothesis testing.\n",
        "-   It provides classes and functions for estimating statistical models.\n",
        "-   It is built on top of libraries such as **NumPy**, **SciPy**, and **pandas**\n",
        "-   <https://www.statsmodels.org/stable/index.html>\n",
        "\n",
        "![](images/statsmodels-logo-v2-horizontal-dark.svg){fig-align=\"center\"}\n",
        "\n",
        "## Load the libraries\n",
        "\n",
        "</br></br>\n",
        "\n",
        "Let's import **statsmodels** into Python together with the other relevant libraries.\n"
      ],
      "id": "cd257662"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| output: false\n",
        "\n",
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm"
      ],
      "id": "21f512c4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multiple linear regression model\n",
        "\n",
        "## Example\n",
        "\n",
        "</br>\n",
        "\n",
        "A group of engineers conducted an experiment to determine the influence of five factors on an appropriate measure of the whiteness of rayon ($Y$). The factors (predictors) are\n",
        "\n",
        "-   $X_1$: acid bath temperature.\n",
        "-   $X_2$: cascade acid concentration.\n",
        "-   $X_3$: water temperature.\n",
        "-   $X_4$: sulfide concentration.\n",
        "-   $X_5$: amount of chlorine bleach.\n",
        "\n",
        "## The dataset\n",
        "\n",
        "</br>\n",
        "\n",
        "The dataset for the file is in \"rayon.xlsx\". It has 26 observations.\n"
      ],
      "id": "8db07412"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| output: true\n",
        "\n",
        "rayon_data = pd.read_excel(\"rayon.xlsx\")\n",
        "rayon_data.head()"
      ],
      "id": "4db7edde",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multiple linear regression model\n",
        "\n",
        "$$Y = f(\\boldsymbol{X}) + \\epsilon$$\n",
        "\n",
        "-   $f(\\boldsymbol{X}) = \\beta_0 + \\beta_1 X_1 + \\cdots + \\beta_p X_p$ (constant).\n",
        "-   $p$ is the number of predictors.\n",
        "-   $\\epsilon$ is a random variable describing everything that is not captured by our model.\n",
        "\n",
        "Assumptions:\n",
        "\n",
        "1.  The expected or average value of $\\epsilon$ is zero.\n",
        "2.  The dispersion or variance of $\\epsilon$ is $\\sigma^2$ (unknown constant).\n",
        "\n",
        "## In our example\n",
        "\n",
        "$$Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_3 + \\beta_4 X_4 + \\beta_5 X_5 + \\epsilon$$\n",
        "\n",
        "::: {style=\"font-size: 90%;\"}\n",
        "-   $X_1$: acid bath temperature.\n",
        "\n",
        "-   $X_2$: cascade acid concentration.\n",
        "\n",
        "-   $X_3$: water temperature.\n",
        "\n",
        "-   $X_4$: sulfide concentration.\n",
        "\n",
        "-   $X_5$: amount of chlorine bleach.\n",
        "\n",
        "-   $Y$: whiteness of rayon.\n",
        "\n",
        "-   $p = 5$ and $\\epsilon$ is the error of the model assumed to be 0 and of constant dispersion $\\sigma^2$.\n",
        ":::\n",
        "\n",
        "## Interpretation of coefficients\n",
        "\n",
        "$$f(\\boldsymbol{X}) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_p X_p,$$\n",
        "\n",
        "where the unknown parameter $\\beta_0$ is called the “intercept,” and $\\beta_j$ is the “coefficient” of the j-th predictor.\n",
        "\n",
        "For the j-th predictor, we have that:\n",
        "\n",
        "-   $\\beta_j = 0$ implies no dependence.\n",
        "-   $\\beta_j > 0$ implies positive dependence.\n",
        "-   $\\beta_j < 0$ implies negative dependence.\n",
        "\n",
        "## \n",
        "\n",
        "</br>\n",
        "\n",
        "$$f(\\boldsymbol{X}) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_p X_p,$$\n",
        "\n",
        "**Interpretation**:\n",
        "\n",
        "-   $\\beta_0$ is the [average response]{style=\"color:blue;\"} when all predictors $X_j$ equal 0.\n",
        "-   $\\beta_j$ is the [amount of increase in the average response]{style=\"color:blue;\"} by a 1 unit increase in the predictor $X_j$, *when all other predictors are fixed to an arbitrary value*.\n",
        "\n",
        "## Training Data\n",
        "\n",
        "The parameters $\\beta_0, \\beta_1, \\ldots, \\beta_p$ and $\\sigma^2$ are unknown. To learn about them, we use our [**training**]{style=\"color:blue;\"} data.\n"
      ],
      "id": "445c56a3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: true\n",
        "\n",
        "rayon_data.head()"
      ],
      "id": "96ab79fe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notation\n",
        "\n",
        "-   $X_{ij}$ denotes the i-th observed value of predictor $X_j$.\n",
        "-   $Y_i$ denotes the i-th observed value of response $Y$.\n"
      ],
      "id": "df081491"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: true\n",
        "\n",
        "rayon_data.head()"
      ],
      "id": "53ef9d39",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \n",
        "\n",
        "</br>\n",
        "\n",
        "Since we believe in the multiple linear regression model, then the observations in the data set must comply with\n",
        "\n",
        "$$Y_i= \\beta_0+\\beta_1 X_{i1} + \\beta_2 X_{i2} + \\cdots + \\beta_p X_{ip} + \\epsilon_i.$$\n",
        "\n",
        "where:\n",
        "\n",
        "-   $i=1, \\ldots, n.$\n",
        "\n",
        "-   $n$ is the number of observations. In our example, $n = 26$.\n",
        "\n",
        "-   The $\\epsilon_1, \\epsilon_2, \\ldots, \\epsilon_n$ are random errors.\n",
        "\n",
        "## Assumptions of the errors\n",
        "\n",
        "$$Y_i= \\beta_0+\\beta_1 X_{i1} + \\beta_2 X_{i2} + \\cdots + \\beta_p X_{ip} + \\epsilon_i $$\n",
        "\n",
        "The error $\\epsilon_i$’s must satisfy the following assumptions:\n",
        "\n",
        "::: incremental\n",
        "1.  On average, they are close to zero for any values of the predictors $X_j$.\n",
        "2.  For any value of a predictor $X_i$, the dispersion or variance is constant and equal to $\\sigma^2$.\n",
        "3.  The $\\epsilon_i$’s are all independent from each other.\n",
        "4.  [The $\\epsilon_i$’s follow normal distribution with mean 0 and variance $\\sigma^2$.]{style=\"color:gray;\"}\n",
        ":::\n",
        "\n",
        "## Questions\n",
        "\n",
        "</br>\n",
        "\n",
        "::: incremental\n",
        "1.  How can we estimate $\\beta_0, \\beta_1, \\ldots, \\beta_p$ and $\\sigma^2$?\n",
        "\n",
        "2.  How can we make inferences about $\\beta_0, \\beta_1, \\ldots, \\beta_p$?\n",
        "\n",
        "3.  How can we validate the model and all its assumptions?\n",
        "\n",
        "4.  How can we make predictions of future responses using the multiple linear regression model?\n",
        ":::\n",
        "\n",
        "## Matrix notation\n",
        "\n",
        "In what follows, it is useful to denote the multiple linear regression model using matrix notation:\n",
        "\n",
        "$\\mathbf{Y} = \\begin{pmatrix} Y_1 \\\\ Y_2 \\\\ \\vdots \\\\ Y_n \\end{pmatrix}$ and $\\mathbf{X} = \\begin{pmatrix}\n",
        "1& X_{11} & X_{12} & \\cdots & X_{1p} \\\\\n",
        "1& X_{21} & X_{22} & \\cdots & X_{2p} \\\\\n",
        "\\vdots &\\vdots & \\vdots & \\cdots & \\vdots \\\\\n",
        "1& X_{n1} & X_{n2} & \\cdots & X_{np} \\\\\n",
        "\\end{pmatrix}$, where\n",
        "\n",
        "-   $\\mathbf{Y}$ is an $n \\times 1$ vector.\n",
        "-   $\\mathbf{X}$ is a $n \\times (p+1)$ matrix.\n",
        "\n",
        "## \n",
        "\n",
        "</br>\n",
        "\n",
        "And,\n",
        "\n",
        "$\\boldsymbol{\\beta} = \\begin{pmatrix}\\beta_0 \\\\ \\beta_1 \\\\ \\vdots \\\\ \\beta_p \\end{pmatrix}$ and $\\boldsymbol{\\epsilon} = \\begin{pmatrix}\\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{pmatrix}$, where\n",
        "\n",
        "-   $\\boldsymbol{\\beta}$ is an $(p+1) \\times 1$ vector.\n",
        "-   $\\boldsymbol{\\epsilon}$ is an $n \\times 1$ vector.\n",
        "\n",
        "## \n",
        "\n",
        "</br>\n",
        "\n",
        "The multiple linear regression model then is\n",
        "\n",
        "$$\\mathbf{Y} =  \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}.$$ This expression means\n",
        "\n",
        "$\\begin{pmatrix} Y_1 \\\\ Y_2 \\\\ \\vdots \\\\ Y_n \\end{pmatrix} = \\begin{pmatrix}\n",
        "\\beta_0 + \\beta_1 X_{11} + \\beta_2 X_{12} + \\cdots + \\beta_p X_{1p} \\\\\n",
        "\\beta_0 + \\beta_1 X_{21} + \\beta_2 X_{22} + \\cdots + \\beta_p X_{2p} \\\\\n",
        "\\vdots  \\\\\n",
        "\\beta_0 + \\beta_1 X_{n1} + \\beta_2 X_{n2} + \\cdots + \\beta_p X_{np} \\\\\n",
        "\\end{pmatrix} + \\begin{pmatrix}\\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{pmatrix}$\n",
        "\n",
        "# Parameter Estimation\n",
        "\n",
        "## An estimator for $\\boldsymbol{\\beta}$\n",
        "\n",
        "Our goal is to find an estimator for the vector $\\boldsymbol{\\beta}$ (and all its components). For the moment, let’s assume that we have one:\n",
        "\n",
        "$\\hat{\\boldsymbol{\\beta}} = \\begin{pmatrix} \\hat{\\beta}_0 \\\\ \\hat{\\beta}_1 \\\\ \\vdots\\\\ \\hat{\\beta}_p \\end{pmatrix}$, where $\\hat{\\beta}_j$ is an estimator for $\\beta_j$, $j = 0, \\ldots, p$.\n",
        "\n",
        "Using this estimator, we can compute the predicted responses of our model $\\hat{\\mathbf{Y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}$, where $\\hat{\\mathbf{Y}} = (\\hat{Y}_1, \\hat{Y}_2, \\ldots, \\hat{Y}_n)^{T}$ and $\\hat{Y}_i$ is the i-th predicted response.\n",
        "\n",
        "## \n",
        "\n",
        "</br>\n",
        "\n",
        "The expression $\\hat{\\mathbf{Y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}$ means\n",
        "\n",
        "$$\\begin{pmatrix} \\hat{Y}_1 \\\\ \\hat{Y}_2 \\\\ \\vdots \\\\ \\hat{Y}_n \\end{pmatrix}  = \\begin{pmatrix}\n",
        "\\hat{\\beta}_0 + X_{11} \\hat{\\beta}_1 + X_{12} \\hat{\\beta}_2 + \\cdots + X_{1p} \\hat{\\beta}_p\\\\\n",
        "\\hat{\\beta}_0 + X_{21} \\hat{\\beta}_1 + X_{22}\\hat{\\beta}_2 + \\cdots + X_{2p}\\hat{\\beta}_p \\\\\n",
        "\\vdots  \\\\\n",
        "\\hat{\\beta}_0 + X_{n1} \\hat{\\beta}_1 + X_{n2}\\hat{\\beta}_2 + \\cdots + X_{np} \\hat{\\beta}_p \\\\\n",
        "\\end{pmatrix}$$\n",
        "\n",
        "## \n",
        "\n",
        "</br> </br>\n",
        "\n",
        "This means that the residuals of the estimated model are\n",
        "\n",
        "$$\\hat{\\boldsymbol{\\epsilon}} = \\mathbf{Y} - \\hat{\\mathbf{Y}} = \\mathbf{Y} - \\mathbf{X} \\hat{\\boldsymbol{\\beta}},$$\n",
        "\n",
        "where $\\hat{\\boldsymbol{\\epsilon}} = (\\hat{\\epsilon}_1, \\hat{\\epsilon}_2, \\ldots, \\hat{\\epsilon}_n)^{T}$ and $\\hat{\\epsilon}_i = Y_i - \\hat{Y}_i$ is the i-th residual.\n",
        "\n",
        "## Least squares estimator\n",
        "\n",
        "To find the best estimator for $\\boldsymbol{\\beta}$ (and all its elements), we use the method of least squares. This method finds the best $\\hat{\\boldsymbol{\\beta}}$ that minimizes the residual sum of squares (RSS):\n",
        "\n",
        "$$RSS = \\left(\\mathbf{y} - \\mathbf{X} \\hat{\\boldsymbol{\\beta}}\\right)^{T} \\left(\\mathbf{y} - \\mathbf{X} \\hat{\\boldsymbol{\\beta}}\\right) = \\sum_{i=1}^{n} \\hat{\\epsilon}^2_i = \\sum_{i=1}^{n} (Y_i - \\hat{Y}_i)^2.$$\n",
        "\n",
        "The estimator that minimizes the expression above is called the [**least squares estimator**]{style=\"color:brown;\"}:\n",
        "\n",
        "$$\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^{T}\\mathbf{X})^{-1} \\mathbf{X}^{T}\\mathbf{y}$$\n",
        "\n",
        "## Computation of $\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^{T}\\mathbf{X})^{-1} \\mathbf{X}^{T}\\mathbf{y}$\n",
        "\n",
        "</br>\n",
        "\n",
        "1.  Compute the transpose of a matrix: $\\mathbf{X}^{T}$.\n",
        "2.  Compute the product of a matrix and a vector: $\\mathbf{X}^{T}\\mathbf{Y}$.\n",
        "3.  Compute the product of two matrices: $\\mathbf{X}^{T} \\mathbf{X}$.\n",
        "4.  Compute the [**inverse**]{style=\"color:red;\"} of a matrix: $(\\mathbf{X}^{T} \\mathbf{X})^{-1}$.\n",
        "\n",
        "## Remarks\n",
        "\n",
        "4.  Compute the [**inverse**]{style=\"color:red;\"} of a matrix: $(\\mathbf{X}^{T} \\mathbf{X})^{-1}$.\n",
        "\n",
        "-   Not all matrices have an inverse.\n",
        "-   If it does not have an inverse then the matrix is called [**singular**]{style=\"color:darkblue;\"}. Otherwise, it is called **non-singular**.\n",
        "-   For the inverse to exist, the columns in $\\mathbf{X}$ must be *linearly independent*.\n",
        "-   Or, equivalently, the determinant $|\\mathbf{X}^{T} \\mathbf{X}| > 0$.\n",
        "\n",
        "## \n",
        "\n",
        "![](images/clipboard-2523519923.png){fig-align=\"center\"}\n",
        "\n",
        "## Computation in Python\n",
        "\n",
        "</br>\n",
        "\n",
        "To compute the least squares estimates, we first split the data set into a matrix with the values of the predictors only, and a matrix with the response values.\n"
      ],
      "id": "e1c2d7d6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| output: true\n",
        "\n",
        "# Matrix with predictors.\n",
        "rayon_predictors = rayon_data.drop(columns=['Y'])\n",
        "\n",
        "# Add intercept.\n",
        "rayon_X_train = sm.add_constant(rayon_predictors)\n",
        "\n",
        "# Matrix with response.\n",
        "rayon_Y_train = rayon_data['Y']"
      ],
      "id": "c41725f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \n",
        "\n",
        "</br></br>\n",
        "\n",
        "Next, we use the functions `OLS()` and `fit()` from **statsmodels**.\n"
      ],
      "id": "ed02321b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| output: false\n",
        "\n",
        "# Create linear regression object\n",
        "regr = sm.OLS(rayon_Y_train, rayon_X_train)\n",
        "\n",
        "# Train the model using the training sets\n",
        "linear_model = regr.fit()"
      ],
      "id": "c79b73b6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \n",
        "\n",
        "</br>\n",
        "\n",
        "To show the estimated coefficients, we use the argument `params` of the `linear_model` object created previously.\n"
      ],
      "id": "e9944934"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| output: true\n",
        "\n",
        "# The estimated coefficients.\n",
        "print(linear_model.params)"
      ],
      "id": "742d84c1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The elements in the vector above are the estimates $\\hat{\\beta}_0$, $\\hat{\\beta}_1$, $\\hat{\\beta}_2$, $\\hat{\\beta}_3$, $\\hat{\\beta}_4$, and $\\hat{\\beta}_5$.\n",
        "\n",
        "## Interpretation of estimated coefficients\n",
        "\n",
        "::: incremental\n",
        "-   The average whiteness of a rayon is $\\hat{\\beta}_0 = -35.26$ when all predictors are equal to 0.\n",
        "\n",
        "-   Increasing the acid bath temperature by 1 unit increases the average whiteness of a rayon by $\\hat{\\beta}_1 = 0.745$ units.\n",
        "\n",
        "-   Increasing the cascade acid concentration by 1 unit increases the average whiteness of a rayon by $\\hat{\\beta}_2 = 20.23$ units.\n",
        ":::\n",
        "\n",
        "## \n",
        "\n",
        "</br></br>\n",
        "\n",
        "-   Increasing the water temperature by 1 unit increases the average whiteness of a rayon by $\\hat{\\beta}_3 = 0.793$ units.\n",
        "\n",
        "-   Increasing the sulfide concentration by 1 unit increases the average whiteness of a rayon by $\\hat{\\beta}_4 = 25.583$ units.\n",
        "\n",
        "-   Increasing the amount of chlorine bleach by 1 unit increases the average whiteness of a rayon by $\\hat{\\beta}_5 = 17.208$ units.\n",
        "\n",
        "## Properties of least squares estimators\n",
        "\n",
        "</br>\n",
        "\n",
        "If all the assumptions of the linear regression model are satisfied, the least squares estimators have some attractive properties.\n",
        "\n",
        ". . .\n",
        "\n",
        "For example:\n",
        "\n",
        "1.  On average, $\\hat{\\beta}_{j}$ equals the true parameter value $\\beta_{j}$.\n",
        "2.  Each $\\hat{\\beta}_{j}$ follows a normal distribution with a specific mean and variance.\n",
        "\n",
        "## Predictions\n",
        "\n",
        "</br>\n",
        "\n",
        "Once we estimate the intercept and model coefficients, we make predictions as follows:\n",
        "\n",
        "$$\\hat{Y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 X_{i1} + \\hat{\\beta}_2 X_{i2} + \\cdots + \\hat{\\beta}_p X_{ip}$$\n",
        "\n",
        "where $\\hat{Y}_i$ is the i-th fitted or predicted response.\n",
        "\n",
        "In Python, we use the argument `fittedvalues` to show the predicted responses of the estimated model.\n"
      ],
      "id": "c8071afc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| output: true\n",
        "\n",
        "# Make predictions using the the model\n",
        "rayon_Y_pred = linear_model.fittedvalues"
      ],
      "id": "44303d9a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \n",
        "\n",
        "</br>\n",
        "\n",
        "Predictions of the 26 observations in the training dataset.\n"
      ],
      "id": "10663098"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| output: true\n",
        "\n",
        "print(rayon_Y_pred)"
      ],
      "id": "b5d41987",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Residuals\n",
        "\n",
        "</br>\n",
        "\n",
        "Now that we have introduced the estimator $\\hat{\\beta}_0, \\hat{\\beta}_1, \\ldots, \\hat{\\beta}_p$, we can be more specific in our terminology of the linear model.\n",
        "\n",
        "</br>\n",
        "\n",
        "The errors of the estimated model are called [**residuals**]{style=\"color:purple;\"} $\\hat{\\epsilon}_i = Y_i - \\hat{Y}_i$, $i = 1, \\ldots, n.$\n",
        "\n",
        "</br>\n",
        "\n",
        "If the model is correct, the residuals $\\hat{\\epsilon}_1, \\hat{\\epsilon}_2, \\ldots, \\hat{\\epsilon}_n$ give us a good idea of the errors $\\epsilon_1, \\epsilon_2, \\ldots, \\epsilon_n$.\n",
        "\n",
        "## \n",
        "\n",
        "In Python, we compute the residuals using the following command.\n"
      ],
      "id": "051ee97f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| output:  true\n",
        "\n",
        "residuals = linear_model.resid\n",
        "\n",
        "print(residuals)"
      ],
      "id": "1b9186a2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Estimation of variance\n",
        "\n",
        "</br>\n",
        "\n",
        "The variance $\\sigma^2$ of the errors is estimated by\n",
        "\n",
        "$$\\hat{\\sigma}^2=\\frac{1}{n-p-1}\\sum_{i=1}^{n} \\hat{\\epsilon}_i^{2}.$$\n",
        "\n",
        "In Python, we compute $\\hat{\\sigma}^2$ as follows.\n"
      ],
      "id": "825a4e4a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| output:  true\n",
        "\n",
        "error_variance = linear_model.scale\n",
        "\n",
        "print( round(error_variance, 3) )"
      ],
      "id": "1918f5f5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \n",
        "\n",
        "</br>\n",
        "\n",
        "The smaller the value of $\\hat{\\sigma}^2$, the closer our predictions are to the actual responses.\n",
        "\n",
        "In practice, it is better to use the standard deviation of the errors. That is,\n",
        "\n",
        "$$\\hat{\\sigma}=\\left(\\frac{1}{n-p-1}\\sum_{i=1}^{n} \\hat{\\epsilon}_i^{2}\\right)^{1/2}.$$ In Python, we compute $\\hat{\\sigma}$ as follows:\n"
      ],
      "id": "d51f27e9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| output:  true\n",
        "\n",
        "print( round(error_variance**(1/2), 3) )"
      ],
      "id": "2ecfe348",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interpretation of $\\hat{\\sigma}$\n",
        "\n",
        "</br></br></br>\n",
        "\n",
        "-   The smaller the $\\hat{\\sigma}$, the closer our predictions are to the actual responses.\n",
        "-   The $\\hat{\\sigma} = 10.292$ implies that, on average, the predictions of our model are off or incorrect by 10.292 mpg.\n",
        "\n",
        "# [Return to main page](https://alanrvazquez.github.io/TEC-IN1002B-Website/)"
      ],
      "id": "29f115d4"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}